{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c35ebdb-7c28-46c9-b106-de9ee8789357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.9.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7cefeb0-c15b-48a7-b4c5-da4884e71d2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the database...\n",
      "Database connection established!\n",
      "Loading transformed data...\n",
      "Transformed data loaded with 9800 rows and 20 columns.\n",
      "Uploading data to the 'superstore_analytics' table...\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "# Define paths for the transformed dataset\n",
    "transformed_dir = r\"C:\\Users\\ADMIN\\Desktop\\Projects\\ETL-Data-Pipeline-for-Global-Superstore-Analytics\\Dataset\\transformed\"\n",
    "transformed_data_path = os.path.join(transformed_dir, \"transformed_data.csv\")\n",
    "\n",
    "# Database configuration\n",
    "DATABASE_TYPE = 'postgresql'\n",
    "DBAPI = 'psycopg2'\n",
    "ENDPOINT = 'localhost'  # Replace with your database endpoint (localhost if running locally)\n",
    "USER = 'postgres'       # Replace with your database username (postgres is default)\n",
    "PASSWORD = 'hellen'     # Replace with your database password\n",
    "PORT = 5434             # Default PostgreSQL port\n",
    "DATABASE = 'etl_superstore'  # The name of the database\n",
    "\n",
    "# Create the engine\n",
    "print(\"Connecting to the database...\")\n",
    "try:\n",
    "    engine = create_engine(f\"postgresql+psycopg2://{USER}:{PASSWORD}@{ENDPOINT}:{PORT}/{DATABASE}\")\n",
    "    # Test connection\n",
    "    connection = engine.connect()\n",
    "    print(\"Database connection established!\")\n",
    "except SQLAlchemyError as e:\n",
    "    print(f\"Error occurred while connecting to the database: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Load transformed data\n",
    "print(\"Loading transformed data...\")\n",
    "try:\n",
    "    transformed_data = pd.read_csv(transformed_data_path)\n",
    "    print(f\"Transformed data loaded with {transformed_data.shape[0]} rows and {transformed_data.shape[1]} columns.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while loading the transformed data: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Define table name\n",
    "TABLE_NAME = 'superstore_analytics'  # You can change the name if needed\n",
    "print(f\"Uploading data to the '{TABLE_NAME}' table...\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243a62a6-5e79-43ac-86e4-5e5b9ddb3bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data to PostgreSQL database using the engine\n",
    "try:\n",
    "    # Upload the DataFrame to SQL using the engine\n",
    "    transformed_data.to_sql(TABLE_NAME, con=engine, if_exists='replace', index=False)\n",
    "    print(\"\\nData successfully loaded into the database!\")\n",
    "except SQLAlchemyError as e:\n",
    "    print(f\"Error occurred while uploading data to the database: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efc7983c-29a0-4fce-a5da-c81d9511459e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Databases: ['postgres', 'weather_db', 'etl_project_db', 'etl_superstore']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Database configuration\n",
    "DATABASE_TYPE = 'postgresql'\n",
    "DBAPI = 'psycopg2'\n",
    "ENDPOINT = 'localhost'  # Replace with your database endpoint\n",
    "USER = 'postgres'       # Replace with your database username\n",
    "PASSWORD = 'hellen'     # Replace with your database password\n",
    "PORT = 5434             # Default PostgreSQL port\n",
    "\n",
    "# Create engine to connect to the PostgreSQL instance (not a specific database)\n",
    "engine = create_engine(f\"postgresql+psycopg2://{USER}:{PASSWORD}@{ENDPOINT}:{PORT}/postgres\")\n",
    "\n",
    "# Query to list databases\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(\"SELECT datname FROM pg_database WHERE datistemplate = false;\")\n",
    "    databases = [row[0] for row in result]\n",
    "    print(f\"Databases: {databases}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9be76c89-6745-4add-bf48-aa004eeb30c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the database...\n",
      "Database connection established!\n",
      "Loading transformed data...\n",
      "Transformed data loaded with 9800 rows and 20 columns.\n",
      "Creating the table 'superstore_analytics'...\n",
      "Table 'superstore_analytics' created successfully!\n",
      "Uploading data to the 'superstore_analytics' table...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_14412\\2484845370.py:82: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  transformed_data.to_sql(TABLE_NAME, con=engine, if_exists='replace', index=False)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Engine' object has no attribute 'cursor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploading data to the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTABLE_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m table...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# Upload the DataFrame to SQL using the engine\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     \u001b[43mtransformed_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTABLE_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreplace\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mData successfully loaded into the database!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SQLAlchemyError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3087\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2889\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2891\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3083\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[1;32m-> 3087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3088\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:842\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    838\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    839\u001b[0m     )\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[0;32m    843\u001b[0m         frame,\n\u001b[0;32m    844\u001b[0m         name,\n\u001b[0;32m    845\u001b[0m         if_exists\u001b[38;5;241m=\u001b[39mif_exists,\n\u001b[0;32m    846\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m    847\u001b[0m         index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m    848\u001b[0m         schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m    849\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    850\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    851\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    852\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    853\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[0;32m    854\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2850\u001b[0m, in \u001b[0;36mSQLiteDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   2839\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmy_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) not a string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2841\u001b[0m table \u001b[38;5;241m=\u001b[39m SQLiteTable(\n\u001b[0;32m   2842\u001b[0m     name,\n\u001b[0;32m   2843\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2848\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   2849\u001b[0m )\n\u001b[1;32m-> 2850\u001b[0m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2851\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39minsert(chunksize, method)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:984\u001b[0m, in \u001b[0;36mSQLTable.create\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 984\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_exists \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfail\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    986\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:970\u001b[0m, in \u001b[0;36mSQLTable.exists\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexists\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpd_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2865\u001b[0m, in \u001b[0;36mSQLiteDatabase.has_table\u001b[1;34m(self, name, schema)\u001b[0m\n\u001b[0;32m   2854\u001b[0m wld \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2855\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   2856\u001b[0m \u001b[38;5;124mSELECT\u001b[39m\n\u001b[0;32m   2857\u001b[0m \u001b[38;5;124m    name\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2862\u001b[0m \u001b[38;5;124m    AND name=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwld\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\n\u001b[0;32m   2863\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m-> 2865\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfetchall()) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2672\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery must be a string unless using sqlalchemy.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2671\u001b[0m args \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [params]\n\u001b[1;32m-> 2672\u001b[0m cur \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcursor\u001b[49m()\n\u001b[0;32m   2673\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2674\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Engine' object has no attribute 'cursor'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "# Define paths for the transformed dataset\n",
    "transformed_dir = r\"C:\\Users\\ADMIN\\Desktop\\Projects\\ETL-Data-Pipeline-for-Global-Superstore-Analytics\\Dataset\\transformed\"\n",
    "transformed_data_path = os.path.join(transformed_dir, \"transformed_data.csv\")\n",
    "\n",
    "# Database configuration\n",
    "DATABASE_TYPE = 'postgresql'\n",
    "DBAPI = 'psycopg2'\n",
    "ENDPOINT = 'localhost'  # Replace with your database endpoint\n",
    "USER = 'postgres'       # Replace with your database username\n",
    "PASSWORD = 'hellen'     # Replace with your database password\n",
    "PORT = 5434             # Default PostgreSQL port\n",
    "DATABASE = 'etl_superstore'  # The name of the database\n",
    "\n",
    "# Create engine\n",
    "print(\"Connecting to the database...\")\n",
    "try:\n",
    "    engine = create_engine(f\"postgresql+psycopg2://{USER}:{PASSWORD}@{ENDPOINT}:{PORT}/{DATABASE}\")\n",
    "    # Test connection\n",
    "    connection = engine.connect()\n",
    "    print(\"Database connection established!\")\n",
    "except SQLAlchemyError as e:\n",
    "    print(f\"Error occurred while connecting to the database: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Load transformed data\n",
    "print(\"Loading transformed data...\")\n",
    "try:\n",
    "    transformed_data = pd.read_csv(transformed_data_path)\n",
    "    print(f\"Transformed data loaded with {transformed_data.shape[0]} rows and {transformed_data.shape[1]} columns.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while loading the transformed data: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Define table name\n",
    "TABLE_NAME = 'superstore_analytics'  # You can change the name if needed\n",
    "print(f\"Creating the table '{TABLE_NAME}'...\")\n",
    "\n",
    "# Create table schema (example)\n",
    "try:\n",
    "    # Define the table creation query\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS superstore_analytics (\n",
    "        Row_ID INT PRIMARY KEY,\n",
    "        Order_ID VARCHAR(50),\n",
    "        Order_Date DATE,\n",
    "        Ship_Date DATE,\n",
    "        Ship_Mode VARCHAR(50),\n",
    "        Customer_ID VARCHAR(50),\n",
    "        Customer_Name VARCHAR(100),\n",
    "        Segment VARCHAR(50),\n",
    "        Country VARCHAR(50),\n",
    "        City VARCHAR(50),\n",
    "        State VARCHAR(50),\n",
    "        Postal_Code VARCHAR(20),  -- Allow NULLs for missing values\n",
    "        Region VARCHAR(50),\n",
    "        Product_ID VARCHAR(50),\n",
    "        Category VARCHAR(50),\n",
    "        Sub_Category VARCHAR(50),\n",
    "        Product_Name VARCHAR(100),\n",
    "        Sales DECIMAL(10, 2),\n",
    "        Sales_Category VARCHAR(50),\n",
    "        iso_3166_1 VARCHAR(10)  -- Allow NULLs for missing values\n",
    "    );\n",
    "    \"\"\"\n",
    "    # Execute the query to create the table\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(create_table_query)\n",
    "        print(f\"Table '{TABLE_NAME}' created successfully!\")\n",
    "except SQLAlchemyError as e:\n",
    "    print(f\"Error occurred while creating the table: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Upload data to PostgreSQL database using the engine\n",
    "print(f\"Uploading data to the '{TABLE_NAME}' table...\")\n",
    "try:\n",
    "    # Upload the DataFrame to SQL using the engine\n",
    "    transformed_data.to_sql(TABLE_NAME, con=engine, if_exists='replace', index=False)\n",
    "    print(\"\\nData successfully loaded into the database!\")\n",
    "except SQLAlchemyError as e:\n",
    "    print(f\"Error occurred while uploading data to the database: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "deb06f04-8041-432c-83c8-1a3625229c23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row ID        Order ID Order Date  Ship Date       Ship Mode Customer ID  \\\n",
      "0       1  CA-2017-152156 2017-08-11 2017-11-11    Second Class    CG-12520   \n",
      "1       2  CA-2017-152156 2017-08-11 2017-11-11    Second Class    CG-12520   \n",
      "2       3  CA-2017-138688 2017-12-06        NaT    Second Class    DV-13045   \n",
      "3       4  US-2016-108966 2016-11-10        NaT  Standard Class    SO-20335   \n",
      "4       5  US-2016-108966 2016-11-10        NaT  Standard Class    SO-20335   \n",
      "\n",
      "     Customer Name    Segment        Country             City       State  \\\n",
      "0      Claire Gute   Consumer  United States        Henderson    Kentucky   \n",
      "1      Claire Gute   Consumer  United States        Henderson    Kentucky   \n",
      "2  Darrin Van Huff  Corporate  United States      Los Angeles  California   \n",
      "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale     Florida   \n",
      "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale     Florida   \n",
      "\n",
      "   Postal Code Region       Product ID         Category Sub-Category  \\\n",
      "0      42420.0  South  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1      42420.0  South  FUR-CH-10000454        Furniture       Chairs   \n",
      "2      90036.0   West  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3      33311.0  South  FUR-TA-10000577        Furniture       Tables   \n",
      "4      33311.0  South  OFF-ST-10000760  Office Supplies      Storage   \n",
      "\n",
      "                                        Product Name     Sales Sales_Category  \n",
      "0                  Bush Somerset Collection Bookcase  261.9600            Low  \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         Medium  \n",
      "2  Self-Adhesive Address Labels for Typewriters b...   14.6200            Low  \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         Medium  \n",
      "4                     Eldon Fold 'N Roll Cart System   22.3680            Low  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9800 entries, 0 to 9799\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Row ID          9800 non-null   int64         \n",
      " 1   Order ID        9800 non-null   object        \n",
      " 2   Order Date      3959 non-null   datetime64[ns]\n",
      " 3   Ship Date       3815 non-null   datetime64[ns]\n",
      " 4   Ship Mode       9800 non-null   object        \n",
      " 5   Customer ID     9800 non-null   object        \n",
      " 6   Customer Name   9800 non-null   object        \n",
      " 7   Segment         9800 non-null   object        \n",
      " 8   Country         9800 non-null   object        \n",
      " 9   City            9800 non-null   object        \n",
      " 10  State           9800 non-null   object        \n",
      " 11  Postal Code     9800 non-null   float64       \n",
      " 12  Region          9800 non-null   object        \n",
      " 13  Product ID      9800 non-null   object        \n",
      " 14  Category        9800 non-null   object        \n",
      " 15  Sub-Category    9800 non-null   object        \n",
      " 16  Product Name    9800 non-null   object        \n",
      " 17  Sales           9800 non-null   float64       \n",
      " 18  Sales_Category  9800 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(2), int64(1), object(14)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "Index(['Row ID', 'Order ID', 'Order Date', 'Ship Date', 'Ship Mode',\n",
      "       'Customer ID', 'Customer Name', 'Segment', 'Country', 'City', 'State',\n",
      "       'Postal Code', 'Region', 'Product ID', 'Category', 'Sub-Category',\n",
      "       'Product Name', 'Sales', 'Sales_Category'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(transformed_data.head())\n",
    "print(transformed_data.info())\n",
    "print(transformed_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32802d3-ba6c-466b-a135-19850cfe74a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Upload the cleaned DataFrame to SQL using the engine\n",
    "    transformed_data.to_sql('superstore_analytics', con=engine, if_exists='replace', index=False)\n",
    "    print(\"\\nData successfully loaded into the database!\")\n",
    "except SQLAlchemyError as e:\n",
    "    print(f\"Error occurred while uploading data to the database: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02ec5f-bb41-4be6-a9c6-d07df6ff30ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
